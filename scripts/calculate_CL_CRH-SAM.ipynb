{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is to calculate regression patterns plotted in Figure 2 in Liu & Grise 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import os\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine yearly CRH data and convert height to pressure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/bjerknes_raid5/cloudsat/CRH_LW_CloudSat_20*.nc'\n",
    "\n",
    "combined_dataset = xr.open_mfdataset(file_path, combine='by_coords')\n",
    "\n",
    "output_file = '/bjerknes_raid5/cloudsat/CRH_LW_CloudSat_combined.nc'\n",
    "combined_dataset.to_netcdf(output_file)\n",
    "\n",
    "print(f\"Combined dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/bjerknes_raid5/cloudsat/CRH_LW_CloudSat_combined.nc'\n",
    "cloudsat_crh_ds = xr.open_dataset(filename)\n",
    "pressure_lev = height2pressure(cloudsat_crh_ds.height.values*1000)\n",
    "cloudsat_crh_ds = cloudsat_crh_ds.assign_coords(pressure_lev=(\"height\", pressure_lev)).swap_dims({\"height\":\"pressure_lev\"}).drop_vars(\"height\")\n",
    "cloudsat_crh_ds = cloudsat_crh_ds.rename({\"pressure_lev\": \"lev\"})\n",
    "# Interpolate to standard pressure levels\n",
    "cloudsat_crh_ds_interped = cloudsat_crh_ds.interp(lev=define_targetlevels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudsat_crh_ds_interped.to_netcdf('/bjerknes_raid5/cloudsat/CRH_LW_CloudSat_combined_interped.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/bjerknes_raid5/cloudsat/radarlidar_monthly_2006-2020.nc'\n",
    "cloudsat_cl_ds = xr.open_dataset(filename)\n",
    "pressure_lev = height2pressure(cloudsat_cl_ds.height.values)\n",
    "cloudsat_cl_ds = cloudsat_cl_ds.assign_coords(pressure_lev=(\"height\", pressure_lev)).swap_dims({\"height\":\"pressure_lev\"}).drop_vars(\"height\")\n",
    "cloudsat_cl_ds = cloudsat_cl_ds.rename({\"pressure_lev\": \"lev\"}).mean(dim='lon')\n",
    "# Interpolate to standard pressure levels\n",
    "cloudsat_cl_ds_interped = cloudsat_cl_ds.interp(lev=define_targetlevels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudsat_cl_ds_interped.to_netcdf('/bjerknes_raid5/cloudsat/CL_CloudSat_monthly_combined_interped.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert clcalipso to pressure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['MIROC6', 'MRI-ESM2-0']:\n",
    "    filename = '/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/clcalipso/clcalipso_CFmon_'+model_name+'_amip_r1i1p1f1_gn_197901-201412_zonalmean.nc'\n",
    "    clcalipso_cl_ds = xr.open_dataset(filename)\n",
    "    pressure_lev = height2pressure(clcalipso_cl_ds.alt40.values)\n",
    "    clcalipso_cl_ds = clcalipso_cl_ds.assign_coords(pressure_lev=(\"alt40\", pressure_lev)).swap_dims({\"alt40\":\"pressure_lev\"}).drop_vars(\"alt40\")\n",
    "    clcalipso_cl_ds = clcalipso_cl_ds.rename({\"pressure_lev\": \"lev\"})\n",
    "    # Interpolate to standard pressure levels\n",
    "    clcalipso_cl_ds_interped = clcalipso_cl_ds.interp(lev=define_targetlevels())\n",
    "    clcalipso_cl_ds_interped.to_netcdf('/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/clcalipso/clcalipso_CFmon_'+model_name+'_amip_r1i1p1f1_gn_197901-201412_zonalmean'+'pressure_levels'+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load monthly SAM index for different models calculated in calculate_SAM_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '../data'\n",
    "with open(os.path.join(save_directory, 'sam_models_monthly_2000_2014.pkl'), 'rb') as f:\n",
    "    sam_models_monthly = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions to calculate regression coefficient and p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_slope_and_pval(x, y):\n",
    "    # Remove NaN values from x and y\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)  # Only keep pairs where neither is NaN\n",
    "    if np.sum(mask) < 2:  # If not enough valid points, return NaN\n",
    "        return np.nan, np.nan\n",
    "    # Perform linear regression using only valid points\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x[mask], y[mask])\n",
    "    return slope, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regression_with_pvalues(file, jet_latitudes_noseason, lat_range, file_type, MERRA2=False, cloudsat=False, cloudsat_CRH=False):\n",
    "    # Load and select time and latitude range based on file type\n",
    "    if cloudsat:\n",
    "        dataset = xr.open_dataset(file).sel(time=slice('2007', '2018')).sel(lat=slice(*lat_range)).mean(dim='lon')\n",
    "        full_time_range = pd.date_range(start=dataset.time.min().values, end=dataset.time.max().values, freq='MS')\n",
    "        dataset = dataset.reindex(time=full_time_range)\n",
    "    elif cloudsat_CRH:\n",
    "        dataset = xr.open_dataset(file).sel(time=slice('2007', '2018')).sel(lat=slice(*lat_range))\n",
    "        full_time_range = pd.date_range(start=dataset.time.min().values, end=dataset.time.max().values, freq='5D')\n",
    "        dataset = dataset.reindex(time=full_time_range)\n",
    "    else:\n",
    "        dataset = xr.open_dataset(file).sel(time=slice('2000', '2014')).sel(lat=slice(*lat_range))\n",
    "    \n",
    "    common_lat_grid = np.arange(-90, 1, 1)\n",
    "    \n",
    "    dayofyear_mean = dataset.groupby('time.dayofyear').mean(dim='time')\n",
    "    anomaly = dataset.groupby('time.dayofyear') - dayofyear_mean\n",
    "    \n",
    "    if file_type == 'cloud_fraction':\n",
    "        if MERRA2:\n",
    "            data_var = anomaly['CLOUD']\n",
    "        elif cloudsat:\n",
    "            data_var = anomaly['cloud_fraction_on_levels']\n",
    "        else:\n",
    "            data_var = anomaly['cl']\n",
    "    elif file_type == 'cloud_radiative_heating':\n",
    "        if MERRA2:\n",
    "            #data_var = anomaly['DTDTLWR'] + anomaly['DTDTSWR'] - anomaly['DTDTLWRCLR'] - anomaly['DTDTSWRCLR']\n",
    "            data_var = anomaly['DTDTLWR'] - anomaly['DTDTLWRCLR']\n",
    "        elif cloudsat_CRH:\n",
    "            data_var = dataset['CRH_LWcloud']\n",
    "        else:\n",
    "            data_var = anomaly['temp_tendency_K_day']\n",
    "    \n",
    "    data_var_interp = data_var.interp(lat=common_lat_grid)\n",
    "    \n",
    "    regression_result = xr.apply_ufunc(\n",
    "        calc_slope_and_pval,\n",
    "        jet_latitudes_noseason,\n",
    "        np.squeeze(data_var_interp),\n",
    "        input_core_dims=[['time'], ['time']],\n",
    "        vectorize=True,\n",
    "        dask='parallelized',\n",
    "        output_core_dims=[[], []],\n",
    "        output_dtypes=[float, float]\n",
    "    )\n",
    "    \n",
    "    regression_coeff, p_values = regression_result\n",
    "    \n",
    "    model_name = file.split('/')[-1].split('_')[2]\n",
    "    if MERRA2:\n",
    "        regression_coeff_da = xr.DataArray(regression_coeff * (86400 if file_type == 'cloud_radiative_heating' else 100),\n",
    "                                           dims=['lev', 'lat'], coords={'lat': common_lat_grid, 'lev': dataset['lev']})\n",
    "        p_values_da = xr.DataArray(p_values, dims=['lev', 'lat'], coords={'lat': common_lat_grid, 'lev': dataset['lev']})\n",
    "    elif cloudsat:\n",
    "        regression_coeff_da = xr.DataArray(regression_coeff.mean(dim = 'doop'), dims=['lat', 'height'], coords={'lat': common_lat_grid, 'height': dataset['height']/1000})\n",
    "        p_values_da = xr.DataArray(p_values.mean(dim = 'doop'), dims=['lat', 'height'], coords={'lat': common_lat_grid, 'height': dataset['height']/1000})\n",
    "    elif cloudsat_CRH:\n",
    "        regression_coeff_da = xr.DataArray(regression_coeff, dims=['lat', 'height'], coords={'lat': common_lat_grid, 'height': dataset['height']})\n",
    "        p_values_da = xr.DataArray(p_values, dims=['lat', 'height'], coords={'lat': common_lat_grid, 'height': dataset['height']})\n",
    "    elif model_name in ['CAS-ESM2-0', 'CIESM']:\n",
    "        regression_coeff_da = xr.DataArray(regression_coeff * 100, dims=['lev', 'lat'],\n",
    "                                           coords={'lat': common_lat_grid, 'lev': dataset['lev'] / 100})\n",
    "        p_values_da = xr.DataArray(p_values, dims=['lev', 'lat'], coords={'lat': common_lat_grid, 'lev': dataset['lev']/100})\n",
    "    else:\n",
    "        if file_type == 'cloud_fraction':\n",
    "            regression_coeff_da = xr.DataArray(regression_coeff, dims=['lev', 'lat'], coords={'lat': common_lat_grid, 'lev': dataset['lev'] / 100})\n",
    "            p_values_da = xr.DataArray(p_values, dims=['lev', 'lat'], coords={'lat': common_lat_grid, 'lev': dataset['lev'] / 100})\n",
    "        else:\n",
    "            regression_coeff_da = xr.DataArray(regression_coeff, dims=['lev', 'lat'],\n",
    "                                           coords={'lat': common_lat_grid, 'lev': dataset['lev']/100})\n",
    "            p_values_da = xr.DataArray(p_values, dims=['lev', 'lat'], coords={'lat': common_lat_grid, 'lev': dataset['lev']/100})\n",
    "    \n",
    "    return regression_coeff_da, p_values_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating for cloud fraction (cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "directory = '/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/'\n",
    "file_names = os.listdir(directory)\n",
    "files = []\n",
    "for file in file_names:\n",
    "     files.append(directory+file)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TaiESM1...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_TaiESM1_zonalmean_interped_pressure_lev.nc\n",
      "Processing IITM-ESM...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_IITM-ESM_zonalmean_interped_pressure_lev.nc\n",
      "Processing HadGEM3-GC31-MM...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_HadGEM3-GC31-MM_zonalmean_interped_pressure_lev.nc\n",
      "Processing KACE-1-0-G...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_KACE-1-0-G_zonalmean_interped_pressure_lev.nc\n",
      "Processing MPI-ESM-1-2-HAM...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_MPI-ESM-1-2-HAM_zonalmean_interped_pressure_lev.nc\n",
      "Processing NorESM2-LM...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_NorESM2-LM_zonalmean_interped_pressure_lev.nc\n",
      "Processing MPI-ESM1-2-LR...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_MPI-ESM1-2-LR_zonalmean_interped_pressure_lev.nc\n",
      "Processing MIROC-ES2L...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_MIROC-ES2L_zonalmean_interped_pressure_lev.nc\n",
      "Processing MPI-ESM1-2-HR...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_MPI-ESM1-2-HR_zonalmean_interped_pressure_lev.nc\n",
      "Processing CMCC-CM2-HR4...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_CMCC-CM2-HR4_zonalmean_interped_pressure_lev.nc\n",
      "Processing BCC-CSM2-MR...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_BCC-CSM2-MR_zonalmean_interped_pressure_lev.nc\n",
      "Processing ACCESS-ESM1-5...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_ACCESS-ESM1-5_zonalmean_interped_pressure_lev.nc\n",
      "Processing SAM0-UNICON...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_SAM0-UNICON_zonalmean_interped_pressure_lev.nc\n",
      "Processing CAS-ESM2-0...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_CAS-ESM2-0_zonalmean_interped_pressure_lev.nc\n",
      "Processing FGOALS-f3-L...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_FGOALS-f3-L_zonalmean_interped_pressure_lev.nc\n",
      "Processing IPSL-CM6A-LR...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_IPSL-CM6A-LR_zonalmean_interped_pressure_lev.nc\n",
      "Processing BCC-ESM1...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_BCC-ESM1_zonalmean_interped_pressure_lev.nc\n",
      "Processing CIESM...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_CIESM_zonalmean_interped_pressure_lev.nc\n",
      "Processing MIROC6...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_MIROC6_zonalmean_interped_pressure_lev.nc\n",
      "Processing CMCC-CM2-SR5...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_CMCC-CM2-SR5_zonalmean_interped_pressure_lev.nc\n",
      "Processing CNRM-ESM2-1...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_CNRM-ESM2-1_zonalmean_interped_pressure_lev.nc\n",
      "Processing HadGEM3-GC31-LL...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_HadGEM3-GC31-LL_zonalmean_interped_pressure_lev.nc\n",
      "Processing ACCESS-CM2...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_ACCESS-CM2_zonalmean_interped_pressure_lev.nc\n",
      "Processing MRI-ESM2-0...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_MRI-ESM2-0_zonalmean_interped_pressure_lev.nc\n",
      "Processing CAMS-CSM1-0...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_CAMS-CSM1-0_zonalmean_interped_pressure_lev.nc\n",
      "Processing CNRM-CM6-1...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_CNRM-CM6-1_zonalmean_interped_pressure_lev.nc\n",
      "Processing NESM3...\n",
      "/bjerknes_raid5/CMIP6_xl7pd/amip_monthly/cl_combined/zonal_mean_interped/cl_amip_NESM3_zonalmean_interped_pressure_lev.nc\n"
     ]
    }
   ],
   "source": [
    "# To store all regression coefficients for model-mean and spread calculation\n",
    "regression_coeffs_list_cl = []\n",
    "regression_coeffs_cl_sam_models = {}\n",
    "regression_coeffs_cl_sam_models_p_values = {}\n",
    "\n",
    "# Define latitude range\n",
    "lat_range = (-90, 0)\n",
    "\n",
    "file_type = 'cloud_fraction'\n",
    "\n",
    "# Loop through each model and plot on corresponding axis\n",
    "i = 0\n",
    "for file in files:\n",
    "    model_name = file.split(\"_\")[8]\n",
    "    if model_name in sam_models_monthly.keys():\n",
    "        print(f'Processing {model_name}...')\n",
    "        print(file)\n",
    "        sam_df = sam_models_monthly[model_name].resample('ME').mean().loc['2000':'2014']\n",
    "        sam_anomaly = (sam_df - sam_df.mean()) / sam_df.std()\n",
    "        regression_coeff, p_values = calculate_regression_with_pvalues(file, sam_anomaly.values, lat_range, file_type)\n",
    "        \n",
    "        # Store regression_coeff for model-mean and spread calculation\n",
    "        regression_coeffs_list_cl.append(regression_coeff)\n",
    "        regression_coeffs_cl_sam_models[model_name] = regression_coeff\n",
    "        regression_coeffs_cl_sam_models_p_values[model_name] = p_values\n",
    "\n",
    "# Calculate the model-mean and inter-model spread (standard deviation)\n",
    "regression_coeffs_stack = np.stack([coeff.values for coeff in regression_coeffs_list_cl])\n",
    "model_mean_coeff = np.mean(regression_coeffs_stack, axis=0)\n",
    "model_spread_coeff = np.std(regression_coeffs_stack, axis=0)\n",
    "\n",
    "# Convert the mean and spread back to xarray DataArray with appropriate coordinates\n",
    "mean_da_cl = xr.DataArray(model_mean_coeff, dims=regression_coeffs_list_cl[0].dims, coords=regression_coeffs_list_cl[0].coords)\n",
    "spread_da_cl = xr.DataArray(model_spread_coeff, dims=regression_coeffs_list_cl[0].dims, coords=regression_coeffs_list_cl[0].coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save regression maps for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '/bjerknes_raid5/CMIP6_xl7pd/data'\n",
    "with open(os.path.join(save_directory, 'regression_maps_cloud_fraction.pkl'), 'wb') as f:\n",
    "    pickle.dump(regression_coeffs_cl_sam_models, f)\n",
    "\n",
    "with open(os.path.join(save_directory, 'regression_maps_cloud_fraction_p_values.pkl'), 'wb') as f:\n",
    "    pickle.dump(regression_coeffs_cl_sam_models_p_values, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating for cloud radiative heating (CRH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/OWC/huiyu/CMIP6/vertical_CRH/interpolated'\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.nc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MRI-ESM2-0...\n",
      "(40, 91)\n",
      "Processing MPI-ESM1-2-LR...\n",
      "(40, 91)\n",
      "Processing MPI-ESM1-2-HR...\n",
      "(40, 91)\n",
      "Processing MPI-ESM-1-2-HAM...\n",
      "(40, 91)\n",
      "Processing MIROC6...\n",
      "(40, 91)\n",
      "Processing INM-CM4-8...\n",
      "(40, 91)\n",
      "Processing INM-CM5-0...\n",
      "(40, 91)\n",
      "Processing BCC-CSM2-MR...\n",
      "(40, 91)\n"
     ]
    }
   ],
   "source": [
    "# To store all regression coefficients for model-mean and spread calculation\n",
    "regression_coeffs_list_crh = []\n",
    "regression_coeffs_crh_sam_models = {}\n",
    "regression_coeffs_crh_sam_models_p_values = {}\n",
    "\n",
    "# Define latitude range\n",
    "lat_range = (-90, 0)\n",
    "\n",
    "file_type = 'cloud_radiative_heating'\n",
    "\n",
    "# Loop through each model and plot on corresponding axis\n",
    "i = 0\n",
    "for file in files:\n",
    "    model_name = file.split(\"/\")[6].split(\"_\")[0]\n",
    "    print(f'Processing {model_name}...')\n",
    "    if model_name in sam_models_monthly.keys():\n",
    "        sam_df = sam_models_monthly[model_name].loc['2000':'2014']\n",
    "        sam_anomaly = (sam_df - sam_df.mean()) / sam_df.std()\n",
    "        regression_coeff, p_values = calculate_regression_with_pvalues(file, sam_anomaly.values, lat_range, file_type)\n",
    "        print(regression_coeff.shape)\n",
    "        \n",
    "        # Store regression_coeff for model-mean and spread calculation\n",
    "        regression_coeffs_list_crh.append(regression_coeff)\n",
    "        regression_coeffs_crh_sam_models[model_name] = regression_coeff\n",
    "        regression_coeffs_crh_sam_models_p_values[model_name] = p_values\n",
    "\n",
    "# Calculate the model-mean and inter-model spread (standard deviation)\n",
    "regression_coeffs_stack = np.stack([coeff.values for coeff in regression_coeffs_list_crh])\n",
    "model_mean_coeff = np.mean(regression_coeffs_stack, axis=0)\n",
    "model_spread_coeff = np.std(regression_coeffs_stack, axis=0)\n",
    "\n",
    "# Convert the mean and spread back to xarray DataArray with appropriate coordinates\n",
    "mean_da_crh = xr.DataArray(model_mean_coeff, dims=regression_coeffs_list_crh[0].dims, coords=regression_coeffs_list_crh[0].coords)\n",
    "spread_da_crh = xr.DataArray(model_spread_coeff, dims=regression_coeffs_list_crh[0].dims, coords=regression_coeffs_list_crh[0].coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '../data'\n",
    "with open(os.path.join(save_directory, 'regression_maps_crh.pkl'), 'wb') as f:\n",
    "    pickle.dump(regression_coeffs_crh_sam_models, f)\n",
    "\n",
    "with open(os.path.join(save_directory, 'regression_maps_crh_p_values.pkl'), 'wb') as f:\n",
    "    pickle.dump(regression_coeffs_crh_sam_models_p_values, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isca_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
